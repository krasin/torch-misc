{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'nngraph'\n",
    "require 'optim'\n",
    "model_utils = require 'third_party.char-rnn.util.model_utils'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Whether to use CUDA, -1: use CPU, >=0: use corresponding GPU\n",
    "gpuid = 0\n",
    "if gpuid >= 0 then\n",
    "    print('using CUDA on GPU ' .. gpuid .. '...')\n",
    "    require 'cutorch'\n",
    "    require 'cunn'\n",
    "    cutorch.setDevice(gpuid + 1) -- note +1 to make it 0 indexed! sigh lua\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFile = 'data/mnist.t7/train_32x32.t7'\n",
    "testFile = 'data/mnist.t7/test_32x32.t7'\n",
    "trainData = torch.load(trainFile,'ascii')\n",
    "testData = torch.load(testFile,'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Train data:')\n",
    "print(trainData.labels[{{1, 6}}])\n",
    "print(\"size: \", trainData.data:size(), trainData.labels:size())\n",
    "itorch.image(trainData.data[{{1, 6}}])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test data:')\n",
    "print(testData.data:size())\n",
    "print(testData.labels[{{1, 6}}])\n",
    "itorch.image(testData.data[{{1, 6}}])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputSize = 32*32\n",
    "layerSize = 200\n",
    "numLabels = 10\n",
    "gradClip = 5\n",
    "mlp = nn.Sequential()\n",
    "mlp:add(nn.Linear(inputSize, layerSize))\n",
    "mlp:add(nn.ReLU(false))\n",
    "mlp:add(nn.Linear(layerSize, numLabels))\n",
    "mlp:add(nn.LogSoftMax())\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "if gpuid >= 0 then\n",
    "    mlp:cuda()\n",
    "    criterion:cuda()\n",
    "end\n",
    "\n",
    "-- Flatten params\n",
    "params, gradParams = model_utils.combine_all_parameters(mlp)\n",
    "print('params: ', params:size(), params:type())\n",
    "print('gradParams: ', gradParams:size(), params:type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "maxBatch = 50000 / batchSize -- hardcoded value for MNIST\n",
    "curBatch = 1\n",
    "\n",
    "function feval(x)\n",
    "    if x ~= params then\n",
    "        params:copy(x)\n",
    "    end\n",
    "    gradParams:zero()\n",
    "    ------------------ get minibatch -------------------\n",
    "    local batchStart = (curBatch-1)*batchSize + 1\n",
    "    local batchEnd = batchStart + batchSize - 1\n",
    "    curBatch = curBatch + 1\n",
    "    if curBatch > maxBatch then\n",
    "        curBatch = 1\n",
    "    end\n",
    "    local x = torch.reshape(trainData.data[{{batchStart, batchEnd}}], batchSize, inputSize)\n",
    "    x = x:float()/127.5 - 1\n",
    "    -- print('feval, x: ', x:size(), x:type())\n",
    "    local y = trainData.labels[{{batchStart, batchEnd}}]\n",
    "    if gpuid >= 0 then\n",
    "        x = x:float():cuda()\n",
    "        y = y:float():cuda()\n",
    "    end\n",
    "\n",
    "    ------------------- forward pass -------------------\n",
    "    prediction = mlp:forward(x)\n",
    "    loss = criterion:forward(prediction, y)\n",
    "\n",
    "    ------------------ backward pass -------------------\n",
    "    dprediction = criterion:backward(prediction, y)\n",
    "    mlp:backward(x, dprediction)\n",
    "    \n",
    "    gradParams:clamp(-gradClip, gradClip)\n",
    "    return loss, gradParams\n",
    "end\n",
    "\n",
    "loss, _ = feval(params)\n",
    "print('loss: ', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local optimState = {learningRate = 0.00001, alpha = 0.95}\n",
    "iterations = 100000\n",
    "\n",
    "for i = 1, iterations do\n",
    "    local _, loss = optim.rmsprop(feval, params, optimState)\n",
    "    trainLoss = loss[1]\n",
    "    if i == 1 or i % 5000 == 0 then\n",
    "        print('i=', i, ' train loss: ', trainLoss)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function predict(input)\n",
    "    --print ('input: ', input:size())\n",
    "    local x = torch.reshape(input, input:size(1), inputSize)\n",
    "    x = x:float()/127.5 - 1\n",
    "    if gpuid >= 0 then\n",
    "        x = x:float():cuda()\n",
    "    end\n",
    "    --print ('x: ', x:size(), x:type())\n",
    "    local prediction = mlp:forward(x)\n",
    "    local _, classes = prediction:max(2)\n",
    "    return classes\n",
    "end\n",
    "classes = predict(trainData.data[{{1, 2}}])\n",
    "print(\"predicted classes: \", classes)\n",
    "print(\"ground truth: \", trainData.labels[{{1, 2}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function evalAccuracy(input, labels)\n",
    "    local matches = 0\n",
    "    local batchSize = 1000\n",
    "    local from = 1\n",
    "    for i = 1, input:size(1) do\n",
    "        if i - from + 1 >= batchSize or i == input:size(1) then\n",
    "            --print ('i=', i, ' from: ', from)\n",
    "            local curLabels = labels[{{from, i}}]\n",
    "            local predictions = predict(input[{{from, i}}], curLabels):float()\n",
    "            --print ('predictions: ', predictions:size(), predictions:type())\n",
    "            curLabels:map(predictions, function(xx, yy) if xx == yy then matches = matches + 1 end end)\n",
    "            from = i+1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return matches / labels:size(1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valAcc = evalAccuracy(trainData.data[{{50001, 60000}}], trainData.labels[{{50001, 60000}}])\n",
    "print('validation accuracy: ', valAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testAcc = evalAccuracy(testData.data, testData.labels)\n",
    "print('test accuracy: ', testAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
