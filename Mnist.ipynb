{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'nngraph'\n",
    "require 'optim'\n",
    "sid = require 'sid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Whether to use CUDA, -1: use CPU, >=0: use corresponding GPU\n",
    "gpuid = 0\n",
    "if gpuid >= 0 then\n",
    "    use_cuda = true\n",
    "    print('using CUDA on GPU ' .. gpuid .. '...')\n",
    "    require 'cutorch'\n",
    "    require 'cunn'\n",
    "    cutorch.setDevice(gpuid + 1) -- note +1 to make it 0 indexed! sigh lua\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFile = 'data/mnist.t7/train_32x32.t7'\n",
    "testFile = 'data/mnist.t7/test_32x32.t7'\n",
    "trainData = torch.load(trainFile,'ascii')\n",
    "trainData.data = trainData.data:float()\n",
    "trainData.labels = trainData.labels:float()\n",
    "valData = { data=trainData.data[{{50001, 60000}}],\n",
    "            labels=trainData.labels[{{50001, 60000}}] }\n",
    "trainData.data = trainData.data[{{1, 50000}}]\n",
    "trainData.labels = trainData.labels[{{1, 50000}}]\n",
    "testData = torch.load(testFile,'ascii')\n",
    "testData.data = testData.data:float()\n",
    "testData.labels = testData.labels:float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Preprocess train, val and test data.\n",
    "\n",
    "-- 1. Calculate mean for train data and subtract the mean from train, val and test data.\n",
    "mean = trainData.data:mean()\n",
    "print('mean: ', mean)\n",
    "trainData.data:add(-mean)\n",
    "valData.data:add(-mean)\n",
    "testData.data:add(-mean)\n",
    "\n",
    "-- 2. Calculate std deviation for train data and divide by it\n",
    "std = trainData.data:std()\n",
    "print('std: ', std)\n",
    "trainData.data:div(std)\n",
    "valData.data:div(std)\n",
    "testData.data:div(std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Train data:')\n",
    "print(trainData.labels[{{1, 6}}])\n",
    "print(\"size: \", trainData.data:size(), trainData.labels:size())\n",
    "itorch.image(trainData.data[{{1, 6}}])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Test data:')\n",
    "print(testData.data:size())\n",
    "print(testData.labels[{{1, 6}}])\n",
    "itorch.image(testData.data[{{1, 6}}])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputSize = 32*32\n",
    "convLayers = 3\n",
    "numConvFilters = 50\n",
    "numLayers = 1\n",
    "layerSize = 400\n",
    "numLabels = 10\n",
    "\n",
    "-- Dropout\n",
    "convDropout = 0.3\n",
    "dropout = 0.5\n",
    "\n",
    "function create_mnist_net(arch, args)\n",
    "    if arch ~= 'mnist_conv' then return nil end\n",
    "\n",
    "    local module = nn.Sequential()\n",
    "    module:add(nn.SpatialConvolution(1, numConvFilters, 5, 5, 1, 1, 2))\n",
    "    module:add(nn.ReLU(false))\n",
    "    module:add(nn.Dropout(convDropout))\n",
    "\n",
    "    for i = 1, convLayers do\n",
    "        module:add(nn.SpatialConvolution(numConvFilters, numConvFilters, 3, 3, 1, 1, 1))\n",
    "        module:add(nn.ReLU(false))\n",
    "        module:add(nn.Dropout(convDropout))\n",
    "    end\n",
    "    \n",
    "    linearInputSize = numConvFilters*inputSize\n",
    "    module:add(nn.Reshape(linearInputSize))\n",
    "\n",
    "    --for i = 1, numLayers do\n",
    "    --    if i == 1 then\n",
    "    --        mlp:add(nn.Linear(linearInputSize, layerSize))\n",
    "    --    else\n",
    "    --        mlp:add(nn.Linear(layerSize, layerSize))\n",
    "    --    end\n",
    "    --    mlp:add(nn.ReLU(false))\n",
    "    --    mlp:add(nn.Dropout(dropout))\n",
    "    --end\n",
    "    --mlp:add(nn.Linear(layerSize, numLabels))\n",
    "\n",
    "    module:add(nn.Linear(linearInputSize, numLabels))\n",
    "    module:add(nn.LogSoftMax())\n",
    "    return module\n",
    "end\n",
    "\n",
    "sid.register_arch('mnist_conv', create_mnist_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dog = sid.create('mnist_conv', nil, use_cuda)\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "if use_cuda then\n",
    "    criterion:cuda()\n",
    "end\n",
    "\n",
    "print('params: ', dog.params:size(), dog.params:type())\n",
    "print('gradParams: ', dog.grad_params:size(), dog.grad_params:type())\n",
    "\n",
    "-- initialization\n",
    "dog.params:uniform(-0.08, 0.08) -- small numbers uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = 1000 / dog.params:size(1) -- L2 regularization strength\n",
    "gradClip = 5\n",
    "\n",
    "batchSize = 50\n",
    "maxBatch = trainData.data:size(1) / batchSize\n",
    "--maxBatch = maxBatch / 10 -- test for overfit; TODO: remove before commit.\n",
    "print('maxBatch: ', maxBatch)\n",
    "curBatch = 1\n",
    "\n",
    "function feval(x)\n",
    "    if x ~= dog.params then\n",
    "        dog.params:copy(x)\n",
    "    end\n",
    "    dog.grad_params:zero()\n",
    "    ------------------ get minibatch -------------------\n",
    "    local batchStart = (curBatch-1)*batchSize + 1\n",
    "    local batchEnd = batchStart + batchSize - 1\n",
    "    curBatch = curBatch + 1\n",
    "    if curBatch > maxBatch then\n",
    "        curBatch = 1\n",
    "    end\n",
    "    --local x = torch.reshape(trainData.data[{{batchStart, batchEnd}}], batchSize, inputSize)\n",
    "    local x = trainData.data[{{batchStart, batchEnd}}]\n",
    "    local y = trainData.labels[{{batchStart, batchEnd}}]\n",
    "    if use_cuda then\n",
    "        x = x:float():cuda()\n",
    "        y = y:float():cuda()\n",
    "    end\n",
    "\n",
    "    ------------------- forward pass -------------------\n",
    "    dog.module:training() -- make sure we are in correct mode \n",
    "    local prediction = dog.module:forward(x)\n",
    "    local paramNorm = dog.params:norm()\n",
    "    local loss = criterion:forward(prediction, y) + reg * paramNorm * paramNorm / 2\n",
    "\n",
    "    ------------------ backward pass -------------------\n",
    "    local dprediction = criterion:backward(prediction, y)\n",
    "    dog.module:backward(x, dprediction)\n",
    "    \n",
    "    dog.grad_params:add(reg, dog.params) -- apply regularization gradient\n",
    "    dog.grad_params:clamp(-gradClip, gradClip)\n",
    "    return loss, dog.grad_params\n",
    "end\n",
    "\n",
    "loss, _ = feval(dog.params)\n",
    "print('loss: ', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimState = {learningRate = 0.0003, alpha = 0.9}\n",
    "learningRateDecay = 0.9\n",
    "learningRateDecayAfter = 10\n",
    "\n",
    "iterations = 2000\n",
    "\n",
    "epoch = 0\n",
    "minLoss = 10\n",
    "maxLoss = 0\n",
    "sumLoss = 0\n",
    "lossCnt = 0\n",
    "\n",
    "for i = 1, iterations do\n",
    "    if curBatch == 1 then\n",
    "        epoch = epoch + 1\n",
    "        if epoch >= learningRateDecayAfter then\n",
    "            optimState.learningRate = optimState.learningRate * learningRateDecay\n",
    "        end\n",
    "        --print(string.format('Starting epoch %d, lr: %f', epoch, optimState.learningRate))\n",
    "    end\n",
    "    local _, loss = optim.rmsprop(feval, dog.params, optimState)\n",
    "    trainLoss = loss[1]\n",
    "    if trainLoss < minLoss then minLoss = trainLoss end\n",
    "    if trainLoss > maxLoss then maxLoss = trainLoss end\n",
    "    sumLoss = sumLoss + trainLoss\n",
    "    lossCnt = lossCnt + 1\n",
    "    if i == 1 or i % 1000 == 0 then\n",
    "        print(string.format('epoch=%d, i=%d, train loss: %f .. %f .. %f, lr: %f',\n",
    "                epoch, i, minLoss, sumLoss / lossCnt, maxLoss, optimState.learningRate))\n",
    "        minLoss = 10\n",
    "        maxLoss = 0\n",
    "        sumLoss = 0\n",
    "        lossCnt = 0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function predict(input)\n",
    "    --print ('input: ', input:size())\n",
    "    --local x = torch.reshape(input, input:size(1), inputSize)\n",
    "    local x = input\n",
    "    if gpuid >= 0 then\n",
    "        x = x:float():cuda()\n",
    "    end\n",
    "    dog.module:evaluate() -- turn off dropout\n",
    "    local prediction = dog.module:forward(x)\n",
    "    local _, classes = prediction:max(2)\n",
    "    return classes\n",
    "end\n",
    "classes = predict(trainData.data[{{1, 2}}])\n",
    "print(\"predicted classes: \", classes)\n",
    "print(\"ground truth: \", trainData.labels[{{1, 2}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function evalAccuracy(input, labels)\n",
    "    local matches = 0\n",
    "    local batchSize = 1000\n",
    "    local from = 1\n",
    "    for i = 1, input:size(1) do\n",
    "        if i - from + 1 >= batchSize or i == input:size(1) then\n",
    "            --print ('i=', i, ' from: ', from)\n",
    "            local curLabels = labels[{{from, i}}]\n",
    "            local predictions = predict(input[{{from, i}}], curLabels):float()\n",
    "            --print ('predictions: ', predictions:size(), predictions:type())\n",
    "            curLabels:map(predictions, function(xx, yy) if xx == yy then matches = matches + 1 end end)\n",
    "            from = i+1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return matches / labels:size(1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainAcc = evalAccuracy(trainData.data, trainData.labels)\n",
    "print('train accuracy: ', trainAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valAcc = evalAccuracy(valData.data, valData.labels)\n",
    "print('validation accuracy: ', valAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testAcc = evalAccuracy(testData.data, testData.labels)\n",
    "print('test accuracy: ', testAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sid.save('mnist.nn', dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dog = sid.load('mnist.nn', use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('dog.params: ', dog.params:size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
